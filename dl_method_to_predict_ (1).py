# -*- coding: utf-8 -*-
"""DL method to predict .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cQlsb-myuBnb7FGpObSS0y0QjELDAZfF

# New Section

##Abstarct
This study presents a deep learning approach using PyTorch to predict breast cancer diagnoses from clinical and imaging-derived features. A publicly available breast cancer dataset was preprocessed by handling missing values, encoding categorical variables, and scaling numerical features. An artificial neural network (ANN) with two hidden layers was designed, employing ReLU activations and a sigmoid output for binary classification. The model was trained for 100 epochs using binary cross-entropy loss and the Adam optimizer. Evaluation on the held-out test set achieved an accuracy of 96.5%, demonstrating the modelâ€™s strong predictive capability. These results indicate that PyTorch-based deep learning models can effectively classify malignant and benign breast cancer cases. The framework can be further extended with hyperparameter optimization, alternative architectures, or cross-validation for enhanced robustness, and it highlights the potential of deep learning to support computer-aided diagnostic systems in oncology.
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np
import pandas as pd

df=pd.read_csv('/content/Breast_cancer_dataset.csv')

"""## Data preprocessing

### Subtask:
Handle missing values if any, encode categorical variables (the 'diagnosis' column), and scale the features. Split the data into training and testing sets.

**Reasoning**:
Inspect the DataFrame for missing values and handle the 'Unnamed: 32' column which has only missing values. Encode the 'diagnosis' column and split the data into features and target.
"""

print(df.isnull().sum())

# The column 'Unnamed: 32' has only missing values, so we drop it.
df = df.drop('Unnamed: 32', axis=1)

# Encode the 'diagnosis' column (M=1, B=0)
df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})

# Separate features (X) and target (y), dropping 'id'
X = df.drop(['id', 'diagnosis'], axis=1)
y = df['diagnosis']

"""**Reasoning**:
Scale the features and split the data into training and testing sets.


"""

# Scale the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

"""## Model definition

### Subtask:
Define a simple deep learning model using PyTorch. This could be a feedforward neural network for this dataset.

**Reasoning**:
Define a PyTorch neural network class for binary classification.
"""

class BreastCancerNet(nn.Module):
    def __init__(self, input_features):
        super(BreastCancerNet, self).__init__()
        self.fc1 = nn.Linear(input_features, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

# Initialize the model
input_features = X_train.shape[1]
model = BreastCancerNet(input_features)

print(model)

"""## Model training

### Subtask:
Train the defined model using the training data. This involves defining a loss function, an optimizer, and iterating over the training data for a number of epochs.

**Reasoning**:
Convert the training data to PyTorch tensors, create a DataLoader, define the loss function and optimizer, and then train the model for a specified number of epochs, printing the loss periodically.
"""

# Convert data to PyTorch tensors
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1) # Ensure correct shape

# Create DataLoader
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# Define Loss Function and Optimizer
criterion = nn.BCELoss() # Binary Cross-Entropy Loss
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training Loop
epochs = 100
model.train() # Set model to training mode

for epoch in range(epochs):
    for inputs, labels in train_loader:
        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    if (epoch+1) % 10 == 0:
        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')

"""## Model evaluation

### Subtask:
Evaluate the trained model on the testing data and calculate the accuracy of the predictions.

**Reasoning**:
Convert test data to tensors, set the model to evaluation mode, and evaluate the model on the test data to calculate accuracy.
"""

# Convert test data to PyTorch tensors
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)

# Set model to evaluation mode
model.eval()

# Disable gradient calculation
with torch.no_grad():
    # Get predictions
    outputs = model(X_test_tensor)
    # Apply threshold to get binary predictions

    predicted = (outputs > 0.5).float()

    # Calculate accuracy
    correct = (predicted == y_test_tensor).sum().item()
    accuracy = correct / y_test_tensor.size(0)

print(f'Accuracy of the model on the test data: {accuracy:.4f}')

"""## Summary:

### Data Analysis Key Findings

*   The 'Unnamed: 32' column was removed from the dataset as it contained only missing values.
*   The 'diagnosis' column was successfully encoded into numerical values, with 'M' mapped to 1 and 'B' mapped to 0.
*   The features were scaled using StandardScaler, and the data was split into training and testing sets with a test size of 20%.
*   A deep learning model with two hidden layers and a sigmoid output layer was defined using PyTorch.
*   The model was trained for 100 epochs using the Binary Cross-Entropy Loss function and the Adam optimizer.
*   The accuracy of the trained model on the test data is 0.9649.

### Insights or Next Steps

*   The high accuracy on the test set suggests the model is performing well in predicting breast cancer based on the provided features.
*   Further steps could involve exploring different model architectures, hyperparameter tuning, or using cross-validation to ensure the robustness of the model's performance.

"""